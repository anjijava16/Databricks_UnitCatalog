{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "96816ed7-b08a-4ca3-abb9-f99880c3535d",
     "showTitle": false,
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "\n",
    "This notebook shows you how to create and query a table or DataFrame loaded from data stored in Azure Blob storage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "84d079e4-93e8-460d-9d95-54a3fa326ca1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "### Step 1: Set the data location and type\n",
    "\n",
    "There are two ways to access Azure Blob storage: account keys and shared access signatures (SAS).\n",
    "\n",
    "To get started, we need to set the location and type of the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c760fc54-dbf0-4715-8df6-8fdff699c029",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "storage_account_name = \"STORAGE_ACCOUNT_NAME\"\n",
    "storage_account_access_key = \"YOUR_ACCESS_KEY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6482be4c-f067-47c9-b0ac-35c938b94601",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "file_location = \"wasbs://example/location\"\n",
    "file_type = \"csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8acc0dda-69e3-4817-bf5d-450562afe113",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.conf.set(\n",
    "  \"fs.azure.account.key.\"+storage_account_name+\".blob.core.windows.net\",\n",
    "  storage_account_access_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "51114086-25f5-4c9c-8bb3-64ff28b0f0f4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "### Step 2: Read the data\n",
    "\n",
    "Now that we have specified our file metadata, we can create a DataFrame. Notice that we use an *option* to specify that we want to infer the schema from the file. We can also explicitly set this to a particular schema if we have one already.\n",
    "\n",
    "First, let's create a DataFrame in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f6366891-7da1-478e-8094-4291f4fca976",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.read.format(file_type).option(\"inferSchema\", \"true\").load(file_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "92108b48-e8f5-4d0d-9d24-3775b36ca207",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "### Step 3: Query the data\n",
    "\n",
    "Now that we have created our DataFrame, we can query it. For instance, you can identify particular columns to select and display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fec0eb47-1220-48a6-81b4-adb261a7265a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(df.select(\"EXAMPLE_COLUMN\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8abe7239-0632-4b90-baf0-38549b038a38",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "### Step 4: (Optional) Create a view or table\n",
    "\n",
    "If you want to query this data as a table, you can simply register it as a *view* or a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "88f300bc-d77c-4cea-b950-fdebb696a3a3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"YOUR_TEMP_VIEW_NAME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8abbb176-6708-4684-86df-50e35b77d223",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "We can query this view using Spark SQL. For instance, we can perform a simple aggregation. Notice how we can use `%sql` to query the view from SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a41b3f47-6033-4512-816a-1bff6b94fae4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "\n",
    "SELECT EXAMPLE_GROUP, SUM(EXAMPLE_AGG) FROM YOUR_TEMP_VIEW_NAME GROUP BY EXAMPLE_GROUP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "be4f71a4-2c5b-4df4-8b5b-16b9c17c057a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "Since this table is registered as a temp view, it will be available only to this notebook. If you'd like other users to be able to query this table, you can also create a table from the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "db9631f6-bb4a-42ca-8a3c-0d48af932331",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.write.format(\"parquet\").saveAsTable(\"MY_PERMANENT_TABLE_NAME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0880bffd-4f8d-4565-8428-ace92f92a53c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "This table will persist across cluster restarts and allow various users across different notebooks to query this data."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "Import from Azure Blob Storage - 2023-09-29",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
